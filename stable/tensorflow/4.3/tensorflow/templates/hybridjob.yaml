apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}
  labels:
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    release: {{ .Release.Name }}
    app: hybridjob
  annotations:
    available_panels: >
      {"GPU温度":"4","GPU功耗":"8","GPU使用率":"6","内存使用率":"7"}
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - port: 1
  selector:
    release: {{ .Release.Name }}
    role: hybridjob
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-exporter
  labels:
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    release: {{ .Release.Name }}
    app: hybridjob
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: "9102"
spec:
  type: ClusterIP
  ports:
  - port: 9102
    targetPort: 9102
    protocol: TCP
    name: exporter
  selector:
    release: {{ .Release.Name }}
    role: hybridjob
---
apiVersion: rivernet.io/v1
kind: HybridJob
metadata:
  name: {{ .Release.Name }}
  labels:
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    release: {{ .Release.Name }}
    role: "hybridjob"
spec:
  replicaSpecs:
  - max: {{ .Values.ps.variables.maxReplicaCount.value }}
    min: {{ .Values.ps.variables.minReplicaCount.value }}
    priority: 1
    template:
      spec:
        restartPolicy: Never
        containers:
      {{- if .Values.psGpu.enabled }}
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}-gpu
      {{- else }}
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}
      {{- end }}
            name: ps
            command: ["bootstrap"]
            args:
            - --role=ps
            - --job_name={{ .Release.Name }}
            - --cmd={{ .Values.cmd.variables.cmd.value }}
            - --log_dir={{.Values.persistence.variables.logDir.value }}
            - --model_dir={{ .Values.persistence.variables.modelDir.value }}
            - --data_dir={{ .Values.persistence.variables.dataDir.value }}
            env:
              - name: PYTHONUNBUFFERED
                value: '1'
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: USE_GPU
            {{- if .Values.psGpu.enabled }}
                value: '1'
            {{- else }}
                value: '0'
            {{- end }}
            ports:
            - containerPort: 2222
              name: app
            - containerPort: 9102
              name: exporter
            resources:
              requests:
                cpu: {{ .Values.ps.variables.cpuRequest.value }}m
                memory: {{ .Values.ps.variables.memoryRequest.value }}Mi
            {{- if .Values.psGpu.enabled }}
              limits:
                nvidia.com/gpu: {{ .Values.psGpu.variables.gpuRequest.value }}
            {{- end }}
            volumeMounts:
            - name: data
              mountPath: {{ .Values.persistence.variables.mountPath.value }}
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.variables.pvc.value }}
        restartPolicy: Never
    tfReplicaType: ps
  - max: {{ .Values.worker.variables.maxReplicaCount.value }}
    min: {{ .Values.worker.variables.minReplicaCount.value }}
    priority: 2
    template:
      spec:
        restartPolicy: Never
        containers:
        {{- if .Values.workerGpu.enabled }}
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}-gpu
        {{- else }}
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}
        {{- end }}
            name: worker
            command: ["bootstrap"]
            args:
            - --role=worker
            - --job_name={{ .Release.Name }}
            - --cmd={{ .Values.cmd.variables.cmd.value }}
            - --log_dir={{.Values.persistence.variables.logDir.value }}
            - --model_dir={{ .Values.persistence.variables.modelDir.value }}
            - --data_dir={{ .Values.persistence.variables.dataDir.value }}
            env:
              - name: PYTHONUNBUFFERED
                value: '1'
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: USE_GPU
            {{- if .Values.workerGpu.enabled }}
                value: '1'
            {{- else }}
                value: '0'
            {{- end }}
            ports:
            - containerPort: 2222
              name: app
            - containerPort: 9102
              name: exporter
            resources:
              requests:
                cpu: {{ .Values.worker.variables.cpuRequest.value }}m
                memory: {{ .Values.worker.variables.memoryRequest.value }}Mi
            {{- if .Values.workerGpu.enabled }}
              limits:
                nvidia.com/gpu: {{ .Values.workerGpu.variables.gpuRequest.value }}
            {{- end }}
            volumeMounts:
            - name: data
              mountPath: {{ .Values.persistence.variables.mountPath.value }}
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.variables.pvc.value }}
    tfReplicaType: worker
