apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}
  labels:
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    release: {{ .Release.Name }}
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: "9102"
    available_panels: >
      {"GPU温度":"4", "GPU功耗":"8", "GPU使用率":"6", "内存使用率":"7"}
spec:
  type: ClusterIP
  ports:
  - port: 9102
    targetPort: 9102
    protocol: TCP
    name: exporter
  selector:
    release: {{ .Release.Name }}
    role: hybridjob
---
apiVersion: rivernet.io/v1
kind: HybridJob
metadata:
  name: {{ .Release.Name }}
  labels:
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    release: {{ .Release.Name }}
    role: "hybridjob"
spec:
  replicaSpecs:
  - max: {{ .Values.ps.variables.maxReplicaCount.value }}
    min: {{ .Values.ps.variables.minReplicaCount.value }}
    priority: 1
    template:
      spec:
        restartPolicy: Never
        containers:
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}
            name: ps
            command: ["bootstrap"]
            args:
            - --role=ps
            - --job_name={{ .Release.Name }}
            - --cmd={{ .Values.cmd.variables.cmd.value }}
            - --log_dir={{.Values.persistence.variables.logDir.value }}
            - --model_dir={{ .Values.persistence.variables.modelDir.value }}
            - --data_dir={{ .Values.persistence.variables.dataDir.value }}
            env:
              - name: PYTHONUNBUFFERED
                value: '1'
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            ports:
            - containerPort: 2222
            resources:
              requests:
                cpu: {{ .Values.ps.variables.cpuRequest.value }}m
                memory: {{ .Values.ps.variables.memoryRequest.value }}Mi
            volumeMounts:
            - name: data
              mountPath: {{ .Values.persistence.variables.mountPath.value }}
          - name: nvidia-smi-exporter
            image: docker.io/rivernet/nvidia-smi-exporter:8.0-runtime-ubuntu14.04
            imagePullPolicy: IfNotPresent
            ports:
            - name: exporter
              containerPort: 9102
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.variables.pvc.value }}
        restartPolicy: Never
    tfReplicaType: ps
  - max: {{ .Values.worker.variables.maxReplicaCount.value }}
    min: {{ .Values.worker.variables.minReplicaCount.value }}
    priority: 2
    template:
      spec:
        restartPolicy: Never
        containers:
          - image: docker.io/rivernet/tensorflow:{{ .Values.version.variables.version.value }}
            name: worker
            command: ["bootstrap"]
            args:
            - --role=worker
            - --job_name={{ .Release.Name }}
            - --cmd={{ .Values.cmd.variables.cmd.value }}
            - --log_dir={{.Values.persistence.variables.logDir.value }}
            - --model_dir={{ .Values.persistence.variables.modelDir.value }}
            - --data_dir={{ .Values.persistence.variables.dataDir.value }}
            env:
              - name: PYTHONUNBUFFERED
                value: '1'
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            ports:
            - containerPort: 2222
            resources:
              requests:
                cpu: {{ .Values.worker.variables.cpuRequest.value }}m
                memory: {{ .Values.worker.variables.memoryRequest.value }}Mi
            volumeMounts:
            - name: data
              mountPath: {{ .Values.persistence.variables.mountPath.value }}
          - name: nvidia-smi-exporter
            image: docker.io/rivernet/nvidia-smi-exporter:8.0-runtime-ubuntu14.04
            imagePullPolicy: IfNotPresent
            ports:
            - name: exporter
              containerPort: 9102
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.variables.pvc.value }}
    tfReplicaType: worker
